data:
  input_type: onehot
  anchor_size: 3000
  anchor_dim: 2
train:
  max_epoch: 50 # The maximum number of training epochs for the model (without early stop)
  patience: 5 # If the model effect doesn't improve after several epochs, training will be stopped early.
  batch_size: 200
  val_batch_size: 500
  learning_rate: 0.001
  decay_epoch: 50
  decay_rate: 0.5
  optimizer: Adam # 'SGD, Adam, AdamW'
model:
  extractor_mode: concat # concat, pairs
  extractor_model: CNN # CNN
  extractor_in_dim: 6000 # anchor_size*2
  extractor_hidden_size: 100
  extractor_output_dim: 100
  extractor_in_ch: 4 # Based on the Encoding method(defualt onehot)
  extractor_conv_kernel_size: 8
  extractor_conv_stride: 1
  extractor_mp_kernel_size: 4
  extractor_mp_stride: 4
  extractor_activite_func: leaky_relu # activite func(relu, softmax, sigmoid, gelu, leaky_relu)
  extractor_slope: 0.01 # slope value when you use leaky relu
  extractor_pool_type: max #max, avg
  extractor_feature_aggregation: fc # avgpool, maxpool
  extractor_feature_agg_rate: 0.5 # 0 means compress the last layer to 1, 
  extractor_flatten: False
  extractor_dropout: 0.0
  extractor_bn: False
  extractor_bn_eps: 0.00001
  extractor_bn_momentum: 0.1
  classifier_input_dim: 100
  classifier_output_dim: 2
  classifier_hidden_size: 100
  classifier_hidden_layer: 2
  classifier_activite_func: leaky_relu # activite func(relu, softmax, sigmoid, gelu, leaky_relu)
  classifier_slope: 0.01 # slope value when you use leaky relu
  classifier_dropout: 0.5
  classifier_bn: False
  classifier_bn_eps: 0.00001
  classifier_bn_momentum: 0.1