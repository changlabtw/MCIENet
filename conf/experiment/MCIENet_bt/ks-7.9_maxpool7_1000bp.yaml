data:
  input_type: onehot
  anchor_size: 1000
  anchor_dim: 2
train:
  max_epoch: 50 # The maximum number of training epochs for the model (without early stop)
  patience: 5 # If the model effect doesn't improve after several epochs, training will be stopped early.
  batch_size: 200
  val_batch_size: 500
  learning_rate: 0.001
  decay_epoch: 50
  decay_rate: 0.5
  optimizer: Adam # 'SGD, Adam, AdamW'
model:
  extractor_mode: concat # concat, pairs
  extractor_model: MCIENet # CNN, Transformer, MCIENet
  extractor_input_lenght: 2000
  extractor_total_channels: 100
  extractor_output_dim: 100
  extractor_in_channels: 4
  extractor_info_retent_chs: 0
  extractor_info_ext_chs_ls: [0.4, 0.4] 
  extractor_info_ext_ks_ls: [7, 9]
  extractor_info_ext_dilation_ls: [1, 1]
  extractor_pool_proj_chs_ls: [0.2]
  extractor_pool_proj_ks_ls: [7]
  extractor_pool_proj_dilation_ls: [1]
  extractor_pool_proj_type_ls: ['maxpool']
  extractor_dim_reduction_pool_ks: 4
  extractor_dim_reduction_pool_stride: 4
  extractor_feature_agg: fc # avgpool, maxpool
  extractor_feature_agg_rate: 0.5 # 0 means compress the last layer to 1, 
  extractor_activite_func: leaky_relu
  extractor_slope: 0.01 # slope value when you use leaky relu
  extractor_dropout: 0.5
  classifier_input_dim: 100
  classifier_output_dim: 2
  classifier_hidden_size: 100
  classifier_hidden_layer: 2
  classifier_activite_func: leaky_relu # activite func(relu, softmax, sigmoid, gelu, leaky_relu)
  classifier_slope: 0.01 # slope value when you use leaky relu
  classifier_dropout: 0.5
  classifier_bn: False
  classifier_bn_eps: 0.00001
  classifier_bn_momentum: 0.1