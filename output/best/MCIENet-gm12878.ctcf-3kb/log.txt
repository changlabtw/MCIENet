[update config]

model.extractor_total_channels: 100 -> 200

model.extractor_dropout: 0.5 -> 0.0

====================
[arguments]
config='conf/MCIENet_final/gm12878_ks7.9-cr2.4.4-maxpool3_3000bp.yaml', input='data/train/gm12878_ctcf/3000bp.50ms.onehot/data.h5', output_folder='output/gm12878_ctcf/2024.08.26_cnn_hyper-test-final-gm12878_ks7.9-cr2.4.4-maxpool3_3000bp/Bp3000_Hl2_Hs100_CHs200_ClfDrop0.5_ExtDrop0.0', device='cuda', eval_freq=1, pin_memory_train=True, save_epoch_out=False, use_state_dict=False, retain_defualt_config=True, save_pred_result=False, model_file='output/gm12878_ctcf/2024.08.26_cnn_hyper-test-final-gm12878_ks7.9-cr2.4.4-maxpool3_3000bp/Bp3000_Hl2_Hs100_CHs200_ClfDrop0.5_ExtDrop0.0\\model.pkl', data={'input_type': 'onehot', 'anchor_size': 3000, 'anchor_dim': 2}, train={'max_epoch': 50, 'patience': 5, 'batch_size': 200, 'val_batch_size': 500, 'learning_rate': 0.001, 'decay_epoch': 50, 'decay_rate': 0.5, 'optimizer': 'adam'}, model={'extractor_mode': 'concat', 'extractor_model': 'mcienet', 'extractor_input_lenght': 6000, 'extractor_total_channels': 200, 'extractor_output_dim': 100, 'extractor_in_channels': 4, 'extractor_info_retent_chs': 0.2, 'extractor_info_ext_chs_ls': [0.2, 0.2], 'extractor_info_ext_ks_ls': [7, 9], 'extractor_info_ext_dilation_ls': [1, 1], 'extractor_pool_proj_chs_ls': [0.4], 'extractor_pool_proj_ks_ls': [3], 'extractor_pool_proj_dilation_ls': [1], 'extractor_pool_proj_type_ls': ['maxpool'], 'extractor_dim_reduction_pool_ks': 4, 'extractor_dim_reduction_pool_stride': 4, 'extractor_feature_agg': 'fc', 'extractor_feature_agg_rate': 0.5, 'extractor_activite_func': 'leaky_relu', 'extractor_slope': 0.01, 'extractor_dropout': 0.0, 'classifier_input_dim': 100, 'classifier_output_dim': 2, 'classifier_hidden_size': 100, 'classifier_hidden_layer': 2, 'classifier_activite_func': 'leaky_relu', 'classifier_slope': 0.01, 'classifier_dropout': 0.5, 'classifier_bn': False, 'classifier_bn_eps': 1e-05, 'classifier_bn_momentum': 0.1}

[System Info]
Computer network name: DESKTOP-B46CAG1
Machine type: AMD64
Processor type: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
Platform type: Windows-10-10.0.22631-SP0
Number of physical cores: 20
Number of logical cores: 28
Max CPU frequency: 3400.0
Train with the cuda(NVIDIA GeForce RTX 4060 Ti)
====================
loading data...
data shape:

	(train)(237888, 2, 4, 3000)

	(val)(27762, 2, 4, 3000)

	(test)(58836, 2, 4, 3000)

data loaded!
====================
compiling model...
LoopModel(
  (data_extractor): MCIENet(
    (Inception1): InceptionLayer(
      (info_retent_branch): BasicConv1d(
        (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
        (activite_func): LeakyReLU(negative_slope=0.01)
      )
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (pool_proj_branchs): ModuleList(
        (0): Sequential(
          (pool_proj_layer): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 80, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (Inception2): InceptionLayer(
      (info_retent_branch): BasicConv1d(
        (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
        (activite_func): LeakyReLU(negative_slope=0.01)
      )
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (pool_proj_branchs): ModuleList(
        (0): Sequential(
          (pool_proj_layer): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 80, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (agg): Sequential(
      (0): Linear(in_features=375, out_features=188, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_ch): Sequential(
      (0): Linear(in_features=188, out_features=1, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_out): Sequential(
      (0): Linear(in_features=200, out_features=100, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (classifier): FeedForward(
    (hidden_net): Sequential(
      (hidden_0): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_0): LeakyReLU(negative_slope=0.01)
      (dropout_0): Dropout(p=0.5, inplace=False)
      (hidden_1): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_1): LeakyReLU(negative_slope=0.01)
      (dropout_1): Dropout(p=0.5, inplace=False)
    )
    (out): Linear(in_features=100, out_features=2, bias=True)
  )
)
==========
======================================================================================================================================================================================
Layer (type (var_name):depth-idx)                                      Input Shape      Output Shape     Param #          Param %          Kernel Shape     Mult-Adds        Trainable
======================================================================================================================================================================================
LoopModel (LoopModel)                                                  [200, 2, 4, 3000] [200, 2]         --                    --          --               --               True
+ MCIENet (data_extractor): 1-1                                        [200, 4, 6000]   [200, 100]       --                    --          --               --               True
|    + InceptionLayer (Inception1): 2-1                                [200, 4, 6000]   [200, 200, 1500] --                    --          --               --               True
|    |    + BasicConv1d (info_retent_branch): 3-1                      [200, 4, 6000]   [200, 40, 6000]  160                0.08%          --               192,000,000      True
|    |    + ModuleList (info_ext_branchs): 3-2                         --               --               25,920            12.74%          --               --               True
|    |    + ModuleList (pool_proj_branchs): 3-3                        --               --               320                0.16%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-4                        [200, 200, 6000] [200, 200, 1500] --                    --          4                --               --
|    + InceptionLayer (Inception2): 2-2                                [200, 200, 1500] [200, 200, 375]  --                    --          --               --               True
|    |    + BasicConv1d (info_retent_branch): 3-5                      [200, 200, 1500] [200, 40, 1500]  8,000              3.93%          --               2,400,000,000    True
|    |    + ModuleList (info_ext_branchs): 3-6                         --               --               41,600            20.45%          --               --               True
|    |    + ModuleList (pool_proj_branchs): 3-7                        --               --               16,000             7.87%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-8                        [200, 200, 1500] [200, 200, 375]  --                    --          4                --               --
|    + Sequential (agg): 2-3                                           [200, 200, 375]  [200, 200, 188]  --                    --          --               --               True
|    |    + Linear (0): 3-9                                            [200, 200, 375]  [200, 200, 188]  70,688            34.76%          --               14,137,600       True
|    |    + LeakyReLU (1): 3-10                                        [200, 200, 188]  [200, 200, 188]  --                    --          --               --               --
|    + Sequential (fc_ch): 2-4                                         [200, 200, 188]  [200, 200, 1]    --                    --          --               --               True
|    |    + Linear (0): 3-11                                           [200, 200, 188]  [200, 200, 1]    189                0.09%          --               37,800           True
|    |    + LeakyReLU (1): 3-12                                        [200, 200, 1]    [200, 200, 1]    --                    --          --               --               --
|    + Sequential (fc_out): 2-5                                        [200, 200]       [200, 100]       --                    --          --               --               True
|    |    + Linear (0): 3-13                                           [200, 200]       [200, 100]       20,100             9.88%          --               4,020,000        True
|    |    + LeakyReLU (1): 3-14                                        [200, 100]       [200, 100]       --                    --          --               --               --
+ FeedForward (classifier): 1-2                                        [200, 100]       [200, 2]         --                    --          --               --               True
|    + Sequential (hidden_net): 2-6                                    [200, 100]       [200, 100]       --                    --          --               --               True
|    |    + Linear (hidden_0): 3-15                                    [200, 100]       [200, 100]       10,100             4.97%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_0): 3-16                          [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Dropout (dropout_0): 3-17                                  [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Linear (hidden_1): 3-18                                    [200, 100]       [200, 100]       10,100             4.97%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_1): 3-19                          [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Dropout (dropout_1): 3-20                                  [200, 100]       [200, 100]       --                    --          --               --               --
|    + Linear (out): 2-7                                               [200, 100]       [200, 2]         202                0.10%          --               40,400           True
======================================================================================================================================================================================
Total params: 203,379
Trainable params: 203,379
Non-trainable params: 0
Total mult-adds (G): 51.38
======================================================================================================================================================================================
Input size (MB): 19.20
Forward/backward pass size (MB): 3420.96
Params size (MB): 0.81
Estimated Total Size (MB): 3440.98
======================================================================================================================================================================================
model loaded!
====================
training model...

2024-08-26 00:39:34 | epoch: 1/50, train loss: 0.4590, val_loss: 0.4465 | training time: 228.4s, inference time: 10.6s
-> Val Loss decrease from inf to 0.446510, saving model

2024-08-26 00:43:17 | epoch: 2/50, train loss: 0.3857, val_loss: 0.3136 | training time: 211.8s, inference time: 10.6s
-> Val Loss decrease from 0.446510 to 0.313552, saving model

2024-08-26 00:47:00 | epoch: 3/50, train loss: 0.3165, val_loss: 0.3079 | training time: 211.7s, inference time: 10.4s
-> Val Loss decrease from 0.313552 to 0.307944, saving model

2024-08-26 00:50:43 | epoch: 4/50, train loss: 0.3022, val_loss: 0.2862 | training time: 211.6s, inference time: 10.4s
-> Val Loss decrease from 0.307944 to 0.286237, saving model

2024-08-26 00:54:24 | epoch: 5/50, train loss: 0.2876, val_loss: 0.2749 | training time: 210.0s, inference time: 10.3s
-> Val Loss decrease from 0.286237 to 0.274930, saving model

2024-08-26 00:58:03 | epoch: 6/50, train loss: 0.2721, val_loss: 0.2644 | training time: 208.1s, inference time: 10.3s
-> Val Loss decrease from 0.274930 to 0.264366, saving model

2024-08-26 01:01:43 | epoch: 7/50, train loss: 0.2376, val_loss: 0.2334 | training time: 208.2s, inference time: 10.3s
-> Val Loss decrease from 0.264366 to 0.233403, saving model

2024-08-26 01:05:22 | epoch: 8/50, train loss: 0.2131, val_loss: 0.2303 | training time: 207.9s, inference time: 10.3s
-> Val Loss decrease from 0.233403 to 0.230258, saving model

2024-08-26 01:09:01 | epoch: 9/50, train loss: 0.2028, val_loss: 0.2233 | training time: 208.2s, inference time: 10.3s
-> Val Loss decrease from 0.230258 to 0.223254, saving model

2024-08-26 01:12:42 | epoch: 10/50, train loss: 0.1923, val_loss: 0.2372 | training time: 209.3s, inference time: 10.6s

2024-08-26 01:16:25 | epoch: 11/50, train loss: 0.1836, val_loss: 0.2298 | training time: 212.2s, inference time: 10.4s

2024-08-26 01:20:08 | epoch: 12/50, train loss: 0.1766, val_loss: 0.2300 | training time: 211.6s, inference time: 10.5s

2024-08-26 01:23:50 | epoch: 13/50, train loss: 0.1690, val_loss: 0.2383 | training time: 210.9s, inference time: 10.3s

2024-08-26 01:27:30 | epoch: 14/50, train loss: 0.1616, val_loss: 0.2507 | training time: 208.5s, inference time: 10.3s
early stop at epoch: 0013
training finish

calculating evaluation...
data shape:

	(train)(237888, 2, 4, 3000)

	(val)(27762, 2, 4, 3000)

	(test)(58836, 2, 4, 3000)

[train]
loss: 0.1864
acc: 0.9253
timeuse: 87.2405
Precision: 0.8313
Recall: 0.6921
Weighted_Precision: 0.9222
Balanced_acc: 0.832
F1: 0.7554
matthews_corrcoef: 0.7158
auPRCs: 0.85
auROC: 0.9581

[val]
loss: 0.2233
acc: 0.91
timeuse: 10.1492
Precision: 0.7752
Recall: 0.6477
Weighted_Precision: 0.9057
Balanced_acc: 0.8051
F1: 0.7058
matthews_corrcoef: 0.6568
auPRCs: 0.7918
auROC: 0.941

[test]
loss: 0.215
acc: 0.9113
timeuse: 21.7208
Precision: 0.7802
Recall: 0.651
Weighted_Precision: 0.9071
Balanced_acc: 0.8072
F1: 0.7098
matthews_corrcoef: 0.6616
auPRCs: 0.8026
auROC: 0.9452

finished!!!

