[update config]

model.extractor_total_channels: 100 -> 300

model.extractor_dropout: 0.5 -> 0.0

model.classifier_hidden_layer: 2 -> 3

====================
[arguments]
config='conf/MCIENet_final/helas3_ks7.9-cr0.10.0-none_1000bp.yaml', input='data/train/helas3_ctcf/1000bp.50ms.onehot/data.h5', output_folder='output/2024.08.25_cnn_hyper-test-helas3_ks7.9-cr0.10.0-none_1000bp/Bp1000_Hl3_Hs100_CHs300_ClfDrop0.5_ExtDrop0.0', device='cuda', eval_freq=1, pin_memory_train=True, save_epoch_out=False, use_state_dict=False, retain_defualt_config=True, save_pred_result=False, model_file='output/2024.08.25_cnn_hyper-test-helas3_ks7.9-cr0.10.0-none_1000bp/Bp1000_Hl3_Hs100_CHs300_ClfDrop0.5_ExtDrop0.0/model.pkl', data={'input_type': 'onehot', 'anchor_size': 1000, 'anchor_dim': 2}, train={'max_epoch': 50, 'patience': 5, 'batch_size': 200, 'val_batch_size': 500, 'learning_rate': 0.001, 'decay_epoch': 50, 'decay_rate': 0.5, 'optimizer': 'adam'}, model={'extractor_mode': 'concat', 'extractor_model': 'mcienet', 'extractor_input_lenght': 2000, 'extractor_total_channels': 300, 'extractor_output_dim': 100, 'extractor_in_channels': 4, 'extractor_info_retent_chs': 0, 'extractor_info_ext_chs_ls': [0.5, 0.5], 'extractor_info_ext_ks_ls': [7, 9], 'extractor_info_ext_dilation_ls': [1, 1], 'extractor_pool_proj_chs_ls': [], 'extractor_pool_proj_ks_ls': [], 'extractor_pool_proj_dilation_ls': [], 'extractor_pool_proj_type_ls': [], 'extractor_dim_reduction_pool_ks': 4, 'extractor_dim_reduction_pool_stride': 4, 'extractor_feature_agg': 'fc', 'extractor_feature_agg_rate': 0.5, 'extractor_activite_func': 'leaky_relu', 'extractor_slope': 0.01, 'extractor_dropout': 0.0, 'classifier_input_dim': 100, 'classifier_output_dim': 2, 'classifier_hidden_size': 100, 'classifier_hidden_layer': 3, 'classifier_activite_func': 'leaky_relu', 'classifier_slope': 0.01, 'classifier_dropout': 0.5, 'classifier_bn': False, 'classifier_bn_eps': 1e-05, 'classifier_bn_momentum': 0.1}

[System Info]
Computer network name: e8bcf11c8754
Machine type: x86_64
Processor type: x86_64
Platform type: Linux-5.15.154+-x86_64-with-glibc2.35
Number of physical cores: 2
Number of logical cores: 4
Max CPU frequency: 0.0
Train with the cuda(Tesla P100-PCIE-16GB)
====================
loading data...
data shape:

	(train)(125627, 2, 4, 1000)

	(val)(16829, 2, 4, 1000)

	(test)(29447, 2, 4, 1000)

data loaded!
====================
compiling model...
LoopModel(
  (data_extractor): MCIENet(
    (Inception1): InceptionLayer(
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 150, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(150, 150, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 150, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(150, 150, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (pool_proj_branchs): ModuleList()
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (Inception2): InceptionLayer(
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(300, 150, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(150, 150, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(300, 150, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(150, 150, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
          )
        )
      )
      (pool_proj_branchs): ModuleList()
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (agg): Sequential(
      (0): Linear(in_features=125, out_features=62, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_ch): Sequential(
      (0): Linear(in_features=62, out_features=1, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_out): Sequential(
      (0): Linear(in_features=300, out_features=100, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (classifier): FeedForward(
    (hidden_net): Sequential(
      (hidden_0): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_0): LeakyReLU(negative_slope=0.01)
      (dropout_0): Dropout(p=0.5, inplace=False)
      (hidden_1): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_1): LeakyReLU(negative_slope=0.01)
      (dropout_1): Dropout(p=0.5, inplace=False)
      (hidden_2): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_2): LeakyReLU(negative_slope=0.01)
      (dropout_2): Dropout(p=0.5, inplace=False)
    )
    (out): Linear(in_features=100, out_features=2, bias=True)
  )
)
==========
=================================================================================================================================================================================
Layer (type (var_name):depth-idx)                                 Input Shape      Output Shape     Param #          Param %          Kernel Shape     Mult-Adds        Trainable
=================================================================================================================================================================================
LoopModel (LoopModel)                                             [200, 2, 4, 1000] [200, 2]         --                    --          --               --               True
+ MCIENet (data_extractor): 1-1                                   [200, 4, 2000]   [200, 100]       --                    --          --               --               True
|    + InceptionLayer (Inception1): 2-1                           [200, 4, 2000]   [200, 300, 500]  --                    --          --               --               True
|    |    + ModuleList (info_ext_branchs): 3-1                    --               --               361,200           41.06%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-2                   [200, 300, 2000] [200, 300, 500]  --                    --          4                --               --
|    + InceptionLayer (Inception2): 2-2                           [200, 300, 500]  [200, 300, 125]  --                    --          --               --               True
|    |    + ModuleList (info_ext_branchs): 3-3                    --               --               450,000           51.16%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-4                   [200, 300, 500]  [200, 300, 125]  --                    --          4                --               --
|    + Sequential (agg): 2-3                                      [200, 300, 125]  [200, 300, 62]   --                    --          --               --               True
|    |    + Linear (0): 3-5                                       [200, 300, 125]  [200, 300, 62]   7,812              0.89%          --               1,562,400        True
|    |    + LeakyReLU (1): 3-6                                    [200, 300, 62]   [200, 300, 62]   --                    --          --               --               --
|    + Sequential (fc_ch): 2-4                                    [200, 300, 62]   [200, 300, 1]    --                    --          --               --               True
|    |    + Linear (0): 3-7                                       [200, 300, 62]   [200, 300, 1]    63                 0.01%          --               12,600           True
|    |    + LeakyReLU (1): 3-8                                    [200, 300, 1]    [200, 300, 1]    --                    --          --               --               --
|    + Sequential (fc_out): 2-5                                   [200, 300]       [200, 100]       --                    --          --               --               True
|    |    + Linear (0): 3-9                                       [200, 300]       [200, 100]       30,100             3.42%          --               6,020,000        True
|    |    + LeakyReLU (1): 3-10                                   [200, 100]       [200, 100]       --                    --          --               --               --
+ FeedForward (classifier): 1-2                                   [200, 100]       [200, 2]         --                    --          --               --               True
|    + Sequential (hidden_net): 2-6                               [200, 100]       [200, 100]       --                    --          --               --               True
|    |    + Linear (hidden_0): 3-11                               [200, 100]       [200, 100]       10,100             1.15%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_0): 3-12                     [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Dropout (dropout_0): 3-13                             [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Linear (hidden_1): 3-14                               [200, 100]       [200, 100]       10,100             1.15%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_1): 3-15                     [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Dropout (dropout_1): 3-16                             [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Linear (hidden_2): 3-17                               [200, 100]       [200, 100]       10,100             1.15%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_2): 3-18                     [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Dropout (dropout_2): 3-19                             [200, 100]       [200, 100]       --                    --          --               --               --
|    + Linear (out): 2-7                                          [200, 100]       [200, 2]         202                0.02%          --               40,400           True
=================================================================================================================================================================================
Total params: 879,677
Trainable params: 879,677
Non-trainable params: 0
Total mult-adds (G): 189.49
=================================================================================================================================================================================
Input size (MB): 6.40
Forward/backward pass size (MB): 2430.88
Params size (MB): 3.52
Estimated Total Size (MB): 2440.80
=================================================================================================================================================================================
model loaded!
====================
training model...

2024-08-25 09:53:21 | epoch: 1/50, train loss: 0.3879, val_loss: 0.2900 | training time: 165.0s, inference time: 4.4s
-> Val Loss decrease from inf to 0.290050, saving model

2024-08-25 09:56:12 | epoch: 2/50, train loss: 0.2834, val_loss: 0.2730 | training time: 164.8s, inference time: 4.5s
-> Val Loss decrease from 0.290050 to 0.272958, saving model

2024-08-25 09:59:03 | epoch: 3/50, train loss: 0.2462, val_loss: 0.2268 | training time: 164.5s, inference time: 4.4s
-> Val Loss decrease from 0.272958 to 0.226845, saving model

2024-08-25 10:01:54 | epoch: 4/50, train loss: 0.2218, val_loss: 0.2238 | training time: 164.7s, inference time: 4.5s
-> Val Loss decrease from 0.226845 to 0.223804, saving model

2024-08-25 10:04:45 | epoch: 5/50, train loss: 0.2065, val_loss: 0.2367 | training time: 164.8s, inference time: 4.5s

2024-08-25 10:07:37 | epoch: 6/50, train loss: 0.1893, val_loss: 0.2336 | training time: 165.0s, inference time: 4.5s

2024-08-25 10:10:28 | epoch: 7/50, train loss: 0.1697, val_loss: 0.2549 | training time: 164.6s, inference time: 4.5s

2024-08-25 10:13:18 | epoch: 8/50, train loss: 0.1490, val_loss: 0.2737 | training time: 164.5s, inference time: 4.4s

2024-08-25 10:16:08 | epoch: 9/50, train loss: 0.1281, val_loss: 0.3036 | training time: 164.0s, inference time: 4.4s
early stop at epoch: 0008
training finish

calculating evaluation...
data shape:

	(train)(125627, 2, 4, 1000)

	(val)(16829, 2, 4, 1000)

	(test)(29447, 2, 4, 1000)

[train]
loss: 0.1964
acc: 0.9181
timeuse: 33.2495
Precision: 0.7579
Recall: 0.7472
Weighted_Precision: 0.9177
Balanced_acc: 0.8498
F1: 0.7525
matthews_corrcoef: 0.7035
auPRCs: 0.8232
auROC: 0.954

[val]
loss: 0.2238
acc: 0.904
timeuse: 4.4699
Precision: 0.7062
Recall: 0.7254
Weighted_Precision: 0.9051
Balanced_acc: 0.8325
F1: 0.7157
matthews_corrcoef: 0.658
auPRCs: 0.7875
auROC: 0.9386

[test]
loss: 0.2268
acc: 0.9032
timeuse: 7.9061
Precision: 0.7098
Recall: 0.7094
Weighted_Precision: 0.9032
Balanced_acc: 0.8257
F1: 0.7096
matthews_corrcoef: 0.6516
auPRCs: 0.7766
auROC: 0.9375

finished!!!

