[update config]

====================
[arguments]
config='output/best/old/BaseCNN-helas3.ctcf-3kb/configures.yaml', input='data/train/helas3_ctcf/3000bp.50ms.onehot/data.h5', output_folder='output/best/BaseCNN-helas3.ctcf-3kb', device='cuda', eval_freq=1, pin_memory_train=True, save_epoch_out=False, use_state_dict=False, retain_defualt_config=True, save_pred_result=False, model_file='output/best/BaseCNN-helas3.ctcf-3kb\\model.pkl', data={'input_type': 'onehot', 'anchor_size': 3000, 'anchor_dim': 2}, train={'max_epoch': 50, 'patience': 5, 'batch_size': 200, 'val_batch_size': 500, 'learning_rate': 0.001, 'decay_epoch': 50, 'decay_rate': 0.5, 'optimizer': 'adam'}, model={'extractor_mode': 'concat', 'extractor_model': 'cnn', 'extractor_in_dim': 6000, 'extractor_hidden_size': 100, 'extractor_output_dim': 100, 'extractor_in_ch': 4, 'extractor_conv_kernel_size': 8, 'extractor_conv_stride': 1, 'extractor_mp_kernel_size': 4, 'extractor_mp_stride': 4, 'extractor_activite_func': 'leaky_relu', 'extractor_slope': 0.01, 'extractor_pool_type': 'max', 'extractor_feature_aggregation': 'fc', 'extractor_feature_agg_rate': 0.5, 'extractor_flatten': False, 'extractor_dropout': 0.3, 'extractor_bn': False, 'extractor_bn_eps': 1e-05, 'extractor_bn_momentum': 0.1, 'classifier_input_dim': 100, 'classifier_output_dim': 2, 'classifier_hidden_size': 100, 'classifier_hidden_layer': 3, 'classifier_activite_func': 'leaky_relu', 'classifier_slope': 0.01, 'classifier_dropout': 0.0, 'classifier_bn': False, 'classifier_bn_eps': 1e-05, 'classifier_bn_momentum': 0.1}

[System Info]
Computer network name: DESKTOP-B46CAG1
Machine type: AMD64
Processor type: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
Platform type: Windows-10-10.0.22631-SP0
Number of physical cores: 20
Number of logical cores: 28
Max CPU frequency: 3400.0
Train with the cuda(NVIDIA GeForce RTX 4060 Ti)
====================
loading data...
data shape:

	(train)(125627, 2, 4, 3000)

	(val)(16829, 2, 4, 3000)

	(test)(29447, 2, 4, 3000)

data loaded!
====================
compiling model...
LoopModel(
  (data_extractor): CNN(
    (conv1): CNNLayer(
      (conv): Conv1d(4, 100, kernel_size=(8,), stride=(1,))
      (activite_func): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.3, inplace=False)
      (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (conv2): CNNLayer(
      (conv): Conv1d(100, 100, kernel_size=(8,), stride=(1,))
      (activite_func): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.3, inplace=False)
      (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (fc_f_agg): Sequential(
      (0): Linear(in_features=372, out_features=186, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_ch): Sequential(
      (0): Linear(in_features=186, out_features=1, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_out): Sequential(
      (0): Linear(in_features=100, out_features=100, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (classifier): FeedForward(
    (hidden_net): Sequential(
      (hidden_0): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_0): LeakyReLU(negative_slope=0.01)
      (hidden_1): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_1): LeakyReLU(negative_slope=0.01)
      (hidden_2): Linear(in_features=100, out_features=100, bias=True)
      (activite_func_2): LeakyReLU(negative_slope=0.01)
    )
    (out): Linear(in_features=100, out_features=2, bias=True)
  )
)
==========
==================================================================================================================================================================
Layer (type (var_name):depth-idx)                  Input Shape      Output Shape     Param #          Param %          Kernel Shape     Mult-Adds        Trainable
==================================================================================================================================================================
LoopModel (LoopModel)                              [200, 2, 4, 3000] [200, 2]         --                    --          --               --               True
+ CNN (data_extractor): 1-1                        [200, 4, 6000]   [200, 100]       --                    --          --               --               True
|    + CNNLayer (conv1): 2-1                       [200, 4, 6000]   [200, 100, 1498] --                    --          --               --               True
|    |    + Conv1d (conv): 3-1                     [200, 4, 6000]   [200, 100, 5993] 3,300              1.70%          [8]              3,955,380,000    True
|    |    + LeakyReLU (activite_func): 3-2         [200, 100, 5993] [200, 100, 5993] --                    --          --               --               --
|    |    + Dropout (dropout): 3-3                 [200, 100, 5993] [200, 100, 5993] --                    --          --               --               --
|    |    + MaxPool1d (pool): 3-4                  [200, 100, 5993] [200, 100, 1498] --                    --          4                --               --
|    + CNNLayer (conv2): 2-2                       [200, 100, 1498] [200, 100, 372]  --                    --          --               --               True
|    |    + Conv1d (conv): 3-5                     [200, 100, 1498] [200, 100, 1491] 80,100            41.38%          [8]              23,885,820,000   True
|    |    + LeakyReLU (activite_func): 3-6         [200, 100, 1491] [200, 100, 1491] --                    --          --               --               --
|    |    + Dropout (dropout): 3-7                 [200, 100, 1491] [200, 100, 1491] --                    --          --               --               --
|    |    + MaxPool1d (pool): 3-8                  [200, 100, 1491] [200, 100, 372]  --                    --          4                --               --
|    + Sequential (fc_f_agg): 2-3                  [200, 100, 372]  [200, 100, 186]  --                    --          --               --               True
|    |    + Linear (0): 3-9                        [200, 100, 372]  [200, 100, 186]  69,378            35.84%          --               13,875,600       True
|    |    + LeakyReLU (1): 3-10                    [200, 100, 186]  [200, 100, 186]  --                    --          --               --               --
|    + Sequential (fc_ch): 2-4                     [200, 100, 186]  [200, 100, 1]    --                    --          --               --               True
|    |    + Linear (0): 3-11                       [200, 100, 186]  [200, 100, 1]    187                0.10%          --               37,400           True
|    |    + LeakyReLU (1): 3-12                    [200, 100, 1]    [200, 100, 1]    --                    --          --               --               --
|    + Sequential (fc_out): 2-5                    [200, 100]       [200, 100]       --                    --          --               --               True
|    |    + Linear (0): 3-13                       [200, 100]       [200, 100]       10,100             5.22%          --               2,020,000        True
|    |    + LeakyReLU (1): 3-14                    [200, 100]       [200, 100]       --                    --          --               --               --
+ FeedForward (classifier): 1-2                    [200, 100]       [200, 2]         --                    --          --               --               True
|    + Sequential (hidden_net): 2-6                [200, 100]       [200, 100]       --                    --          --               --               True
|    |    + Linear (hidden_0): 3-15                [200, 100]       [200, 100]       10,100             5.22%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_0): 3-16      [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Linear (hidden_1): 3-17                [200, 100]       [200, 100]       10,100             5.22%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_1): 3-18      [200, 100]       [200, 100]       --                    --          --               --               --
|    |    + Linear (hidden_2): 3-19                [200, 100]       [200, 100]       10,100             5.22%          --               2,020,000        True
|    |    + LeakyReLU (activite_func_2): 3-20      [200, 100]       [200, 100]       --                    --          --               --               --
|    + Linear (out): 2-7                           [200, 100]       [200, 2]         202                0.10%          --               40,400           True
==================================================================================================================================================================
Total params: 193,567
Trainable params: 193,567
Non-trainable params: 0
Total mult-adds (G): 27.86
==================================================================================================================================================================
Input size (MB): 19.20
Forward/backward pass size (MB): 1228.00
Params size (MB): 0.77
Estimated Total Size (MB): 1247.98
==================================================================================================================================================================
model loaded!
====================
training model...

2024-10-04 10:51:35 | epoch: 1/50, train loss: 0.4355, val_loss: 0.3702 | training time: 82.7s, inference time: 5.0s
-> Val Loss decrease from inf to 0.370190, saving model

2024-10-04 10:52:55 | epoch: 2/50, train loss: 0.3255, val_loss: 0.3075 | training time: 74.9s, inference time: 5.0s
-> Val Loss decrease from 0.370190 to 0.307466, saving model

2024-10-04 10:54:15 | epoch: 3/50, train loss: 0.2939, val_loss: 0.3010 | training time: 74.5s, inference time: 4.8s
-> Val Loss decrease from 0.307466 to 0.300989, saving model

2024-10-04 10:55:35 | epoch: 4/50, train loss: 0.2689, val_loss: 0.3101 | training time: 74.7s, inference time: 4.8s

2024-10-04 10:56:54 | epoch: 5/50, train loss: 0.2513, val_loss: 0.2906 | training time: 74.1s, inference time: 4.9s
-> Val Loss decrease from 0.300989 to 0.290611, saving model

2024-10-04 10:58:14 | epoch: 6/50, train loss: 0.2348, val_loss: 0.2601 | training time: 74.2s, inference time: 4.8s
-> Val Loss decrease from 0.290611 to 0.260147, saving model

2024-10-04 10:59:34 | epoch: 7/50, train loss: 0.2168, val_loss: 0.2334 | training time: 74.7s, inference time: 4.9s
-> Val Loss decrease from 0.260147 to 0.233415, saving model

2024-10-04 11:00:54 | epoch: 8/50, train loss: 0.2031, val_loss: 0.2354 | training time: 74.1s, inference time: 5.0s

2024-10-04 11:02:14 | epoch: 9/50, train loss: 0.1935, val_loss: 0.2393 | training time: 74.7s, inference time: 4.9s

2024-10-04 11:03:33 | epoch: 10/50, train loss: 0.1863, val_loss: 0.2225 | training time: 74.2s, inference time: 4.9s
-> Val Loss decrease from 0.233415 to 0.222545, saving model

2024-10-04 11:04:53 | epoch: 11/50, train loss: 0.1784, val_loss: 0.2429 | training time: 74.1s, inference time: 4.9s

2024-10-04 11:06:12 | epoch: 12/50, train loss: 0.1703, val_loss: 0.2443 | training time: 74.2s, inference time: 4.8s

2024-10-04 11:07:31 | epoch: 13/50, train loss: 0.1628, val_loss: 0.2446 | training time: 73.7s, inference time: 4.9s

2024-10-04 11:08:51 | epoch: 14/50, train loss: 0.1554, val_loss: 0.2477 | training time: 74.0s, inference time: 4.9s

2024-10-04 11:10:10 | epoch: 15/50, train loss: 0.1478, val_loss: 0.2600 | training time: 74.2s, inference time: 5.2s
early stop at epoch: 0014
training finish

calculating evaluation...
data shape:

	(train)(125627, 2, 4, 3000)

	(val)(16829, 2, 4, 3000)

	(test)(29447, 2, 4, 3000)

[train]
loss: 0.1567
acc: 0.939
timeuse: 35.7797
Precision: 0.8498
Recall: 0.7699
Weighted_Precision: 0.9373
Balanced_acc: 0.8714
F1: 0.8079
matthews_corrcoef: 0.7731
auPRCs: 0.8849
auROC: 0.9705

[val]
loss: 0.2225
acc: 0.9081
timeuse: 4.7164
Precision: 0.7405
Recall: 0.6901
Weighted_Precision: 0.9058
Balanced_acc: 0.8209
F1: 0.7144
matthews_corrcoef: 0.6603
auPRCs: 0.7932
auROC: 0.9396

[test]
loss: 0.2359
acc: 0.9081
timeuse: 8.4132
Precision: 0.749
Recall: 0.6745
Weighted_Precision: 0.905
Balanced_acc: 0.8147
F1: 0.7098
matthews_corrcoef: 0.6567
auPRCs: 0.7764
auROC: 0.9324

finished!!!

