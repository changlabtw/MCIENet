[update config]

model.extractor_total_channels: 100 -> 200

model.extractor_output_dim: 100 -> 200

model.extractor_dropout: 0.5 -> 0.3

model.classifier_input_dim: 100 -> 200

model.classifier_hidden_size: 100 -> 200

model.classifier_hidden_layer: 2 -> 4

====================
[arguments]
config='conf/MCIENet_final/gm12878_ks7.9-cr2.4.4-maxpool3_1000bp.yaml', input='data/train/gm12878_ctcf/1000bp.50ms.onehot/data.h5', output_folder='output/2024.08.25_cnn_hyper-test-gm12878_ks7.9-cr2.4.4-maxpool3_1000bp/Bp1000_Hl4_Hs200_CHs200_ClfDrop0.5_ExtDrop0.3', device='cuda', eval_freq=1, pin_memory_train=True, save_epoch_out=False, use_state_dict=False, retain_defualt_config=True, save_pred_result=False, model_file='output/2024.08.25_cnn_hyper-test-gm12878_ks7.9-cr2.4.4-maxpool3_1000bp/Bp1000_Hl4_Hs200_CHs200_ClfDrop0.5_ExtDrop0.3/model.pkl', data={'input_type': 'onehot', 'anchor_size': 1000, 'anchor_dim': 2}, train={'max_epoch': 50, 'patience': 5, 'batch_size': 200, 'val_batch_size': 500, 'learning_rate': 0.001, 'decay_epoch': 50, 'decay_rate': 0.5, 'optimizer': 'adam'}, model={'extractor_mode': 'concat', 'extractor_model': 'mcienet', 'extractor_input_lenght': 2000, 'extractor_total_channels': 200, 'extractor_output_dim': 200, 'extractor_in_channels': 4, 'extractor_info_retent_chs': 0.2, 'extractor_info_ext_chs_ls': [0.2, 0.2], 'extractor_info_ext_ks_ls': [7, 9], 'extractor_info_ext_dilation_ls': [1, 1], 'extractor_pool_proj_chs_ls': [0.4], 'extractor_pool_proj_ks_ls': [3], 'extractor_pool_proj_dilation_ls': [1], 'extractor_pool_proj_type_ls': ['maxpool'], 'extractor_dim_reduction_pool_ks': 4, 'extractor_dim_reduction_pool_stride': 4, 'extractor_feature_agg': 'fc', 'extractor_feature_agg_rate': 0.5, 'extractor_activite_func': 'leaky_relu', 'extractor_slope': 0.01, 'extractor_dropout': 0.3, 'classifier_input_dim': 200, 'classifier_output_dim': 2, 'classifier_hidden_size': 200, 'classifier_hidden_layer': 4, 'classifier_activite_func': 'leaky_relu', 'classifier_slope': 0.01, 'classifier_dropout': 0.5, 'classifier_bn': False, 'classifier_bn_eps': 1e-05, 'classifier_bn_momentum': 0.1}

[System Info]
Computer network name: 1b88e8ec7814
Machine type: x86_64
Processor type: x86_64
Platform type: Linux-5.15.154+-x86_64-with-glibc2.35
Number of physical cores: 2
Number of logical cores: 4
Max CPU frequency: 0.0
Train with the cuda(Tesla P100-PCIE-16GB)
====================
loading data...
data shape:

	(train)(237888, 2, 4, 1000)

	(val)(27762, 2, 4, 1000)

	(test)(58836, 2, 4, 1000)

data loaded!
====================
compiling model...
LoopModel(
  (data_extractor): MCIENet(
    (Inception1): InceptionLayer(
      (info_retent_branch): BasicConv1d(
        (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
        (activite_func): LeakyReLU(negative_slope=0.01)
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (pool_proj_branchs): ModuleList(
        (0): Sequential(
          (pool_proj_layer): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(4, 80, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (Inception2): InceptionLayer(
      (info_retent_branch): BasicConv1d(
        (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
        (activite_func): LeakyReLU(negative_slope=0.01)
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (info_ext_branchs): ModuleList(
        (0): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
        (1): Sequential(
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 40, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
          (info_extract_layer): BasicConv1d(
            (conv): Conv1d(40, 40, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (pool_proj_branchs): ModuleList(
        (0): Sequential(
          (pool_proj_layer): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
          (channel_adjust_layer): BasicConv1d(
            (conv): Conv1d(200, 80, kernel_size=(1,), stride=(1,), bias=False)
            (activite_func): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (dim_reduction_pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (agg): Sequential(
      (0): Linear(in_features=125, out_features=62, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_ch): Sequential(
      (0): Linear(in_features=62, out_features=1, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_out): Sequential(
      (0): Linear(in_features=200, out_features=200, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (classifier): FeedForward(
    (hidden_net): Sequential(
      (hidden_0): Linear(in_features=200, out_features=200, bias=True)
      (activite_func_0): LeakyReLU(negative_slope=0.01)
      (dropout_0): Dropout(p=0.5, inplace=False)
      (hidden_1): Linear(in_features=200, out_features=200, bias=True)
      (activite_func_1): LeakyReLU(negative_slope=0.01)
      (dropout_1): Dropout(p=0.5, inplace=False)
      (hidden_2): Linear(in_features=200, out_features=200, bias=True)
      (activite_func_2): LeakyReLU(negative_slope=0.01)
      (dropout_2): Dropout(p=0.5, inplace=False)
      (hidden_3): Linear(in_features=200, out_features=200, bias=True)
      (activite_func_3): LeakyReLU(negative_slope=0.01)
      (dropout_3): Dropout(p=0.5, inplace=False)
    )
    (out): Linear(in_features=200, out_features=2, bias=True)
  )
)
==========
======================================================================================================================================================================================
Layer (type (var_name):depth-idx)                                      Input Shape      Output Shape     Param #          Param %          Kernel Shape     Mult-Adds        Trainable
======================================================================================================================================================================================
LoopModel (LoopModel)                                                  [200, 2, 4, 1000] [200, 2]         --                    --          --               --               True
+ MCIENet (data_extractor): 1-1                                        [200, 4, 2000]   [200, 200]       --                    --          --               --               True
|    + InceptionLayer (Inception1): 2-1                                [200, 4, 2000]   [200, 200, 500]  --                    --          --               --               True
|    |    + BasicConv1d (info_retent_branch): 3-1                      [200, 4, 2000]   [200, 40, 2000]  160                0.05%          --               64,000,000       True
|    |    + ModuleList (info_ext_branchs): 3-2                         --               --               25,920             8.60%          --               --               True
|    |    + ModuleList (pool_proj_branchs): 3-3                        --               --               320                0.11%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-4                        [200, 200, 2000] [200, 200, 500]  --                    --          4                --               --
|    + InceptionLayer (Inception2): 2-2                                [200, 200, 500]  [200, 200, 125]  --                    --          --               --               True
|    |    + BasicConv1d (info_retent_branch): 3-5                      [200, 200, 500]  [200, 40, 500]   8,000              2.66%          --               800,000,000      True
|    |    + ModuleList (info_ext_branchs): 3-6                         --               --               41,600            13.81%          --               --               True
|    |    + ModuleList (pool_proj_branchs): 3-7                        --               --               16,000             5.31%          --               --               True
|    |    + MaxPool1d (dim_reduction_pool): 3-8                        [200, 200, 500]  [200, 200, 125]  --                    --          4                --               --
|    + Sequential (agg): 2-3                                           [200, 200, 125]  [200, 200, 62]   --                    --          --               --               True
|    |    + Linear (0): 3-9                                            [200, 200, 125]  [200, 200, 62]   7,812              2.59%          --               1,562,400        True
|    |    + LeakyReLU (1): 3-10                                        [200, 200, 62]   [200, 200, 62]   --                    --          --               --               --
|    + Sequential (fc_ch): 2-4                                         [200, 200, 62]   [200, 200, 1]    --                    --          --               --               True
|    |    + Linear (0): 3-11                                           [200, 200, 62]   [200, 200, 1]    63                 0.02%          --               12,600           True
|    |    + LeakyReLU (1): 3-12                                        [200, 200, 1]    [200, 200, 1]    --                    --          --               --               --
|    + Sequential (fc_out): 2-5                                        [200, 200]       [200, 200]       --                    --          --               --               True
|    |    + Linear (0): 3-13                                           [200, 200]       [200, 200]       40,200            13.34%          --               8,040,000        True
|    |    + LeakyReLU (1): 3-14                                        [200, 200]       [200, 200]       --                    --          --               --               --
+ FeedForward (classifier): 1-2                                        [200, 200]       [200, 2]         --                    --          --               --               True
|    + Sequential (hidden_net): 2-6                                    [200, 200]       [200, 200]       --                    --          --               --               True
|    |    + Linear (hidden_0): 3-15                                    [200, 200]       [200, 200]       40,200            13.34%          --               8,040,000        True
|    |    + LeakyReLU (activite_func_0): 3-16                          [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Dropout (dropout_0): 3-17                                  [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Linear (hidden_1): 3-18                                    [200, 200]       [200, 200]       40,200            13.34%          --               8,040,000        True
|    |    + LeakyReLU (activite_func_1): 3-19                          [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Dropout (dropout_1): 3-20                                  [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Linear (hidden_2): 3-21                                    [200, 200]       [200, 200]       40,200            13.34%          --               8,040,000        True
|    |    + LeakyReLU (activite_func_2): 3-22                          [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Dropout (dropout_2): 3-23                                  [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Linear (hidden_3): 3-24                                    [200, 200]       [200, 200]       40,200            13.34%          --               8,040,000        True
|    |    + LeakyReLU (activite_func_3): 3-25                          [200, 200]       [200, 200]       --                    --          --               --               --
|    |    + Dropout (dropout_3): 3-26                                  [200, 200]       [200, 200]       --                    --          --               --               --
|    + Linear (out): 2-7                                               [200, 200]       [200, 2]         402                0.13%          --               80,400           True
======================================================================================================================================================================================
Total params: 301,277
Trainable params: 301,277
Non-trainable params: 0
Total mult-adds (G): 17.16
======================================================================================================================================================================================
Input size (MB): 6.40
Forward/backward pass size (MB): 1141.76
Params size (MB): 1.21
Estimated Total Size (MB): 1149.37
======================================================================================================================================================================================
model loaded!
====================
training model...

2024-08-25 14:08:16 | epoch: 1/50, train loss: 0.4461, val_loss: 0.3646 | training time: 151.3s, inference time: 4.3s
-> Val Loss decrease from inf to 0.364606, saving model

2024-08-25 14:10:54 | epoch: 2/50, train loss: 0.3408, val_loss: 0.3146 | training time: 150.8s, inference time: 4.1s
-> Val Loss decrease from 0.364606 to 0.314627, saving model

2024-08-25 14:13:32 | epoch: 3/50, train loss: 0.3147, val_loss: 0.2965 | training time: 150.7s, inference time: 4.1s
-> Val Loss decrease from 0.314627 to 0.296472, saving model

2024-08-25 14:16:10 | epoch: 4/50, train loss: 0.2889, val_loss: 0.2892 | training time: 150.7s, inference time: 4.1s
-> Val Loss decrease from 0.296472 to 0.289243, saving model

2024-08-25 14:18:49 | epoch: 5/50, train loss: 0.2725, val_loss: 0.2811 | training time: 150.7s, inference time: 4.1s
-> Val Loss decrease from 0.289243 to 0.281087, saving model

2024-08-25 14:21:27 | epoch: 6/50, train loss: 0.2626, val_loss: 0.2746 | training time: 150.7s, inference time: 4.0s
-> Val Loss decrease from 0.281087 to 0.274555, saving model

2024-08-25 14:24:05 | epoch: 7/50, train loss: 0.2519, val_loss: 0.2815 | training time: 150.2s, inference time: 4.0s

2024-08-25 14:26:42 | epoch: 8/50, train loss: 0.2412, val_loss: 0.2924 | training time: 149.6s, inference time: 4.0s

2024-08-25 14:29:20 | epoch: 9/50, train loss: 0.2316, val_loss: 0.3010 | training time: 150.6s, inference time: 4.0s

2024-08-25 14:31:59 | epoch: 10/50, train loss: 0.2202, val_loss: 0.3104 | training time: 150.4s, inference time: 4.1s

2024-08-25 14:34:37 | epoch: 11/50, train loss: 0.2076, val_loss: 0.3224 | training time: 151.1s, inference time: 4.0s
early stop at epoch: 0010
training finish

calculating evaluation...
data shape:

	(train)(237888, 2, 4, 1000)

	(val)(27762, 2, 4, 1000)

	(test)(58836, 2, 4, 1000)

[train]
loss: 0.2464
acc: 0.8994
timeuse: 34.4555
Precision: 0.7693
Recall: 0.5663
Weighted_Precision: 0.8929
Balanced_acc: 0.7662
F1: 0.6524
matthews_corrcoef: 0.6047
auPRCs: 0.7484
auROC: 0.9247

[val]
loss: 0.2746
acc: 0.8858
timeuse: 4.0566
Precision: 0.7258
Recall: 0.5062
Weighted_Precision: 0.8767
Balanced_acc: 0.734
F1: 0.5964
matthews_corrcoef: 0.5441
auPRCs: 0.6794
auROC: 0.9012

[test]
loss: 0.2697
acc: 0.8879
timeuse: 8.4784
Precision: 0.725
Recall: 0.5277
Weighted_Precision: 0.8795
Balanced_acc: 0.7439
F1: 0.6108
matthews_corrcoef: 0.5567
auPRCs: 0.689
auROC: 0.9053

finished!!!

