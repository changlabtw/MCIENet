[update config]

====================
[arguments]
config='output/best/old/BaseCNN-helas3.ctcf-1kb/configures.yaml', input='data/train/helas3_ctcf/1000bp.50ms.onehot/data.h5', output_folder='output/2024.10.05_basecnn_1000bp-rerun-best', device='cuda', eval_freq=1, pin_memory_train=True, save_epoch_out=False, use_state_dict=False, retain_defualt_config=True, save_pred_result=False, model_file='output/2024.10.05_basecnn_1000bp-rerun-best/model.pkl', data={'input_type': 'onehot', 'anchor_size': 1000, 'anchor_dim': 2}, train={'max_epoch': 50, 'patience': 5, 'batch_size': 200, 'val_batch_size': 500, 'learning_rate': 0.001, 'decay_epoch': 50, 'decay_rate': 0.5, 'optimizer': 'adam'}, model={'extractor_mode': 'concat', 'extractor_model': 'cnn', 'extractor_in_dim': 2000, 'extractor_hidden_size': 100, 'extractor_output_dim': 200, 'extractor_in_ch': 4, 'extractor_conv_kernel_size': 8, 'extractor_conv_stride': 1, 'extractor_mp_kernel_size': 4, 'extractor_mp_stride': 4, 'extractor_activite_func': 'leaky_relu', 'extractor_slope': 0.01, 'extractor_pool_type': 'max', 'extractor_feature_aggregation': 'fc', 'extractor_feature_agg_rate': 0.5, 'extractor_flatten': False, 'extractor_dropout': 0.3, 'extractor_bn': False, 'extractor_bn_eps': 1e-05, 'extractor_bn_momentum': 0.1, 'classifier_input_dim': 200, 'classifier_output_dim': 2, 'classifier_hidden_size': 200, 'classifier_hidden_layer': 1, 'classifier_activite_func': 'leaky_relu', 'classifier_slope': 0.01, 'classifier_dropout': 0.0, 'classifier_bn': False, 'classifier_bn_eps': 1e-05, 'classifier_bn_momentum': 0.1}

[System Info]
Computer network name: 12eda3fac1de
Machine type: x86_64
Processor type: x86_64
Platform type: Linux-5.15.154+-x86_64-with-glibc2.35
Number of physical cores: 2
Number of logical cores: 4
Max CPU frequency: 0.0
Train with the cuda(Tesla P100-PCIE-16GB)
====================
loading data...
data shape:

	(train)(125627, 2, 4, 1000)

	(val)(16829, 2, 4, 1000)

	(test)(29447, 2, 4, 1000)

data loaded!
====================
compiling model...
LoopModel(
  (data_extractor): CNN(
    (conv1): CNNLayer(
      (conv): Conv1d(4, 100, kernel_size=(8,), stride=(1,))
      (activite_func): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.3, inplace=False)
      (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (conv2): CNNLayer(
      (conv): Conv1d(100, 100, kernel_size=(8,), stride=(1,))
      (activite_func): LeakyReLU(negative_slope=0.01)
      (dropout): Dropout(p=0.3, inplace=False)
      (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    )
    (fc_f_agg): Sequential(
      (0): Linear(in_features=122, out_features=61, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_ch): Sequential(
      (0): Linear(in_features=61, out_features=1, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (fc_out): Sequential(
      (0): Linear(in_features=100, out_features=200, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (classifier): FeedForward(
    (hidden_net): Sequential(
      (hidden_0): Linear(in_features=200, out_features=200, bias=True)
      (activite_func_0): LeakyReLU(negative_slope=0.01)
    )
    (out): Linear(in_features=200, out_features=2, bias=True)
  )
)
==========
==================================================================================================================================================================
Layer (type (var_name):depth-idx)                  Input Shape      Output Shape     Param #          Param %          Kernel Shape     Mult-Adds        Trainable
==================================================================================================================================================================
LoopModel (LoopModel)                              [200, 2, 4, 1000] [200, 2]         --                    --          --               --               True
+ CNN (data_extractor): 1-1                        [200, 4, 2000]   [200, 200]       --                    --          --               --               True
|    + CNNLayer (conv1): 2-1                       [200, 4, 2000]   [200, 100, 498]  --                    --          --               --               True
|    |    + Conv1d (conv): 3-1                     [200, 4, 2000]   [200, 100, 1993] 3,300              2.17%          [8]              1,315,380,000    True
|    |    + LeakyReLU (activite_func): 3-2         [200, 100, 1993] [200, 100, 1993] --                    --          --               --               --
|    |    + Dropout (dropout): 3-3                 [200, 100, 1993] [200, 100, 1993] --                    --          --               --               --
|    |    + MaxPool1d (pool): 3-4                  [200, 100, 1993] [200, 100, 498]  --                    --          4                --               --
|    + CNNLayer (conv2): 2-2                       [200, 100, 498]  [200, 100, 122]  --                    --          --               --               True
|    |    + Conv1d (conv): 3-5                     [200, 100, 498]  [200, 100, 491]  80,100            52.78%          [8]              7,865,820,000    True
|    |    + LeakyReLU (activite_func): 3-6         [200, 100, 491]  [200, 100, 491]  --                    --          --               --               --
|    |    + Dropout (dropout): 3-7                 [200, 100, 491]  [200, 100, 491]  --                    --          --               --               --
|    |    + MaxPool1d (pool): 3-8                  [200, 100, 491]  [200, 100, 122]  --                    --          4                --               --
|    + Sequential (fc_f_agg): 2-3                  [200, 100, 122]  [200, 100, 61]   --                    --          --               --               True
|    |    + Linear (0): 3-9                        [200, 100, 122]  [200, 100, 61]   7,503              4.94%          --               1,500,600        True
|    |    + LeakyReLU (1): 3-10                    [200, 100, 61]   [200, 100, 61]   --                    --          --               --               --
|    + Sequential (fc_ch): 2-4                     [200, 100, 61]   [200, 100, 1]    --                    --          --               --               True
|    |    + Linear (0): 3-11                       [200, 100, 61]   [200, 100, 1]    62                 0.04%          --               12,400           True
|    |    + LeakyReLU (1): 3-12                    [200, 100, 1]    [200, 100, 1]    --                    --          --               --               --
|    + Sequential (fc_out): 2-5                    [200, 100]       [200, 200]       --                    --          --               --               True
|    |    + Linear (0): 3-13                       [200, 100]       [200, 200]       20,200            13.31%          --               4,040,000        True
|    |    + LeakyReLU (1): 3-14                    [200, 200]       [200, 200]       --                    --          --               --               --
+ FeedForward (classifier): 1-2                    [200, 200]       [200, 2]         --                    --          --               --               True
|    + Sequential (hidden_net): 2-6                [200, 200]       [200, 200]       --                    --          --               --               True
|    |    + Linear (hidden_0): 3-15                [200, 200]       [200, 200]       40,200            26.49%          --               8,040,000        True
|    |    + LeakyReLU (activite_func_0): 3-16      [200, 200]       [200, 200]       --                    --          --               --               --
|    + Linear (out): 2-7                           [200, 200]       [200, 2]         402                0.26%          --               80,400           True
==================================================================================================================================================================
Total params: 151,767
Trainable params: 151,767
Non-trainable params: 0
Total mult-adds (G): 9.19
==================================================================================================================================================================
Input size (MB): 6.40
Forward/backward pass size (MB): 408.00
Params size (MB): 0.61
Estimated Total Size (MB): 415.01
==================================================================================================================================================================
model loaded!
====================
training model...

2024-10-06 06:03:57 | epoch: 1/50, train loss: 0.4016, val_loss: 0.3090 | training time: 25.7s, inference time: 1.5s
-> Val Loss decrease from inf to 0.309003, saving model

2024-10-06 06:04:25 | epoch: 2/50, train loss: 0.3000, val_loss: 0.2888 | training time: 25.1s, inference time: 1.5s
-> Val Loss decrease from 0.309003 to 0.288754, saving model

2024-10-06 06:04:53 | epoch: 3/50, train loss: 0.2764, val_loss: 0.2836 | training time: 25.0s, inference time: 1.5s
-> Val Loss decrease from 0.288754 to 0.283649, saving model

2024-10-06 06:05:22 | epoch: 4/50, train loss: 0.2636, val_loss: 0.2568 | training time: 24.9s, inference time: 1.5s
-> Val Loss decrease from 0.283649 to 0.256805, saving model

2024-10-06 06:05:50 | epoch: 5/50, train loss: 0.2478, val_loss: 0.2384 | training time: 25.0s, inference time: 1.5s
-> Val Loss decrease from 0.256805 to 0.238386, saving model

2024-10-06 06:06:18 | epoch: 6/50, train loss: 0.2322, val_loss: 0.2308 | training time: 24.8s, inference time: 1.9s
-> Val Loss decrease from 0.238386 to 0.230825, saving model

2024-10-06 06:06:46 | epoch: 7/50, train loss: 0.2236, val_loss: 0.2297 | training time: 24.6s, inference time: 1.6s
-> Val Loss decrease from 0.230825 to 0.229656, saving model

2024-10-06 06:07:14 | epoch: 8/50, train loss: 0.2167, val_loss: 0.2279 | training time: 25.0s, inference time: 1.5s
-> Val Loss decrease from 0.229656 to 0.227937, saving model

2024-10-06 06:07:42 | epoch: 9/50, train loss: 0.2118, val_loss: 0.2213 | training time: 24.6s, inference time: 1.5s
-> Val Loss decrease from 0.227937 to 0.221253, saving model

2024-10-06 06:08:11 | epoch: 10/50, train loss: 0.2070, val_loss: 0.2242 | training time: 24.8s, inference time: 2.0s

2024-10-06 06:08:39 | epoch: 11/50, train loss: 0.2029, val_loss: 0.2255 | training time: 24.7s, inference time: 1.5s

2024-10-06 06:09:07 | epoch: 12/50, train loss: 0.1992, val_loss: 0.2245 | training time: 24.7s, inference time: 1.5s

2024-10-06 06:09:35 | epoch: 13/50, train loss: 0.1959, val_loss: 0.2293 | training time: 25.2s, inference time: 1.5s

2024-10-06 06:10:03 | epoch: 14/50, train loss: 0.1921, val_loss: 0.2270 | training time: 24.7s, inference time: 1.6s
early stop at epoch: 0013
training finish

calculating evaluation...
data shape:

	(train)(125627, 2, 4, 1000)

	(val)(16829, 2, 4, 1000)

	(test)(29447, 2, 4, 1000)

[train]
loss: 0.1814
acc: 0.9262
timeuse: 11.6733
Precision: 0.793
Recall: 0.7536
Weighted_Precision: 0.9249
Balanced_acc: 0.8571
F1: 0.7728
matthews_corrcoef: 0.7291
auPRCs: 0.8458
auROC: 0.9622

[val]
loss: 0.2213
acc: 0.9078
timeuse: 1.5644
Precision: 0.7325
Recall: 0.7033
Weighted_Precision: 0.9064
Balanced_acc: 0.826
F1: 0.7176
matthews_corrcoef: 0.6627
auPRCs: 0.7877
auROC: 0.9395

[test]
loss: 0.2287
acc: 0.906
timeuse: 2.7047
Precision: 0.7356
Recall: 0.6805
Weighted_Precision: 0.9035
Balanced_acc: 0.8158
F1: 0.707
matthews_corrcoef: 0.6518
auPRCs: 0.7729
auROC: 0.9352

finished!!!

